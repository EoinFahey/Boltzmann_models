{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "fRh9GEiKPqVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "gc94xtMM1Bdn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive_path = '/content/gdrive/MyDrive/Boltzmann_machines'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7OIjKxDCOaT",
        "outputId": "3c78d0fd-9c83-423f-85f6-25dcc1e1fe0f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load sets\n",
        "# Paths\n",
        "movies_file = os.path.join(drive_path, 'ml-1m/movies.dat')\n",
        "users_file = os.path.join(drive_path, 'ml-1m/users.dat')\n",
        "ratings_file = os.path.join(drive_path, 'ml-1m/ratings.dat')\n",
        "\n",
        "#Load\n",
        "movies = pd.read_csv(movies_file, sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "users = pd.read_csv(users_file, sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "ratings = pd.read_csv(ratings_file, sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "\n",
        "# Display\n",
        "print(' MOVIES', movies.head(3), '\\n\\n', 'USERS', users.head(3), '\\n\\n', 'RATINGS', ratings.head(3))"
      ],
      "metadata": {
        "id": "7zKrBjDW8V-A",
        "outputId": "6b8c78e8-3bed-42f9-c3c3-24e035bde4f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " MOVIES    0                        1                             2\n",
            "0  1         Toy Story (1995)   Animation|Children's|Comedy\n",
            "1  2           Jumanji (1995)  Adventure|Children's|Fantasy\n",
            "2  3  Grumpier Old Men (1995)                Comedy|Romance \n",
            "\n",
            " USERS    0  1   2   3      4\n",
            "0  1  F   1  10  48067\n",
            "1  2  M  56  16  70072\n",
            "2  3  M  25  15  55117 \n",
            "\n",
            " RATINGS    0     1  2          3\n",
            "0  1  1193  5  978300760\n",
            "1  1   661  3  978302109\n",
            "2  1   914  3  978301968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training and test sets\n",
        "\n",
        "# Paths\n",
        "training_set_file = os.path.join(drive_path, 'ml-100k/u1.base')\n",
        "test_set_file = os.path.join(drive_path, 'ml-100k/u1.test')\n",
        "\n",
        "# Load\n",
        "# 0th is row, 1st column = user, 2nd = movie, 3rd = rating, 4th = timestamp\n",
        "training_set = pd.read_csv(training_set_file, delimiter = '\\t')\n",
        "test_set = pd.read_csv(test_set_file, delimiter = '\\t')\n",
        "\n",
        "# Display\n",
        "print(' TRAINING', training_set.head(3), '\\n\\n', 'TESTING', test_set.head(3))\n",
        "\n",
        "# Turn to arrays (same values still)\n",
        "training_set = np.array(training_set, dtype = 'int')\n",
        "test_set = np.array(test_set, dtype = 'int')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZBgMH7HBkeq",
        "outputId": "eb0401ca-0af9-45fb-ec5a-3d52dbc1abee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TRAINING    1  1.1  5  874965758\n",
            "0  1    2  3  876893171\n",
            "1  1    3  4  878542960\n",
            "2  1    4  3  876893119 \n",
            "\n",
            " TESTING    1   6  5  887431973\n",
            "0  1  10  3  875693118\n",
            "1  1  12  5  878542960\n",
            "2  1  14  5  874965706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get total number of users and movies, across\n",
        "# Gives total across train and test data (cross-validation)\n",
        "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
        "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
      ],
      "metadata": {
        "id": "ePkmK0J1HWFw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data into array with a user on each line and movies in columns\n",
        "def convert(data):\n",
        "    # Create list of list. Each list corresponds to a user, and their movie ratings\n",
        "    new_data = []\n",
        "    # Add ratings into user's list\n",
        "    for id_users in range(1, nb_users + 1):\n",
        "      id_movies = data[:, 1][data[:, 0] == id_users]\n",
        "      id_ratings = data[:, 2][data[:, 0] == id_users]\n",
        "      # Fill with zeros\n",
        "      ratings = np.zeros(nb_movies)\n",
        "      # Replace zeros with real ratings\n",
        "      ratings[id_movies - 1] = id_ratings\n",
        "      new_data.append(list(ratings))\n",
        "    return new_data\n",
        "\n",
        "# Contains 943 rows of lists. In each list is the user's ratings of each movie\n",
        "# Moves without a rating just have a 0\n",
        "training_set = convert(training_set)\n",
        "training_set = convert(test_set)"
      ],
      "metadata": {
        "id": "7yyCKXLYJW9P"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data into Torch tensors to enable manipulation in PyTorch\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "metadata": {
        "id": "d5-oVnIkM1H_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Up to here, all the data preprocessing could be used for other types of models. After here, it's specific to Botlzmann models"
      ],
      "metadata": {
        "id": "O5SrDBvdN6zC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert ratings into binary (1 = liked, 0 = not liked, -1 = no rating)\n",
        "training_set[training_set == 0] = -1\n",
        "training_set[training_set == 1] = 0\n",
        "training_set[training_set == 2] = 0\n",
        "training_set[training_set >= 3] = 1\n",
        "\n",
        "test_set[test_set == 0] = -1\n",
        "test_set[test_set == 1] = 0\n",
        "test_set[test_set == 2] = 0\n",
        "test_set[test_set >= 3] = 1"
      ],
      "metadata": {
        "id": "m9adBwqGOGtH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boltzmann model"
      ],
      "metadata": {
        "id": "QuTwCNGCPwSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RBM():\n",
        "  # Self reference, visible nodes, hidden nodes\n",
        "  def __init__(self, nv, nh):\n",
        "    # Initialise weights\n",
        "    self.W = torch.randn(nh, nv)\n",
        "    # Probability of hidden nodes, given visible nodes. 1 = batch, nh = bias\n",
        "    self.a = torch.randn(1, nh)\n",
        "    # Bias for visible nodes\n",
        "    self.b = torch.randn(1, nv)\n",
        "  # Calculate probability that hidden neuron h = 1 given the visible neuron\n",
        "  def sample_h(self, x):\n",
        "    # Make product of two tensors. 'mm' does this for two torch tensors. x = visible neuron, w = tensor of weights\n",
        "    wx = torch.mm(x, self.W.t())\n",
        "    # Activation function. wx + bias. Apply bias to each line of mini-batch using expand_as\n",
        "    activation = wx + self.a.expand_as(wx)\n",
        "    # Probability that hidden node is activated, given visible node. Calculated as sigmoid of activation\n",
        "    p_h_given_v = torch.sigmoid(activation)\n",
        "    # If random number is below 70%, activate neuron, otherwise don't. Gives 0 & 1\n",
        "    return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
        "  # Calculate probability that visible neuron v = 1 given the hidden neuron\n",
        "  def sample_v(self, y):\n",
        "    # Transpose not needed. W is weight matrix of pv given h so you need transpose for ph given v. Here it's just pv given h though so no transpose\n",
        "    wy = torch.mm(y, self.W())\n",
        "    # b, not a\n",
        "    activation = wy.self.b.expand_as(wy)\n",
        "    p_v_given_h = torch.sigmoid(activation)\n",
        "    # From vector of probabilities, give some sampling. If random number from sampling is below 0.25, give 1, otherwise 0\n",
        "    # Depending on 0 or 1, this is the prediction of whether or not user will give a like\n",
        "    return p_v_given_h, torch.bernoulli(p_v_given_h)\n"
      ],
      "metadata": {
        "id": "4YWB9U9rPyh2"
      },
      "execution_count": 21,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}